{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pankajtandon/Gist/blob/main/gist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7y2oZUyJSAaL"
      },
      "source": [
        "This notebook will show you a way to build your app iteratively in Colab.\n",
        "\n",
        "To run this notebook, navigate to \n",
        "https://colab.research.google.com\n",
        "and File | Open this notebook or simply click on the link above.\n",
        "\n",
        "\n",
        "To prevent your API Keyes from being committed to source control, do the following:\n",
        "- Create a directory in the root of your Google Drive and call it `colab_content`.\n",
        "- Create a file in that directory called `api-keys.txt` and in that file add contents like:\n",
        "```\n",
        "OPENAI_API_KEY=<your key>. \n",
        "NGROK_AUTH_TOKEN=<your key>\n",
        "```\n",
        "\n",
        "For OPENAI_API_KEY, you will need to create an account at https://platform.openai.com and it will cost you but it's usually pennies for moderate usage and usage can be monitored at https://platform.openai.com/account/usage\n",
        "The NGROK_AUTH_TOKEN is free and can be gotten from https://ngrok.com/\n",
        "\n",
        "\n",
        "Then run each cell in this notebook in order by looking at the comment in each cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AajPb-2VmqYB",
        "outputId": "3b75b10c-45e3-43dd-a172-158a52d4bb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# First mount a directory in Google Drive. This will help keep your API Keys out of source control.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIzvaKoTm3Gd"
      },
      "outputs": [],
      "source": [
        "# This will need to be done everytime your VM disconnects.\n",
        "\n",
        "!pip install pyngrok\n",
        "!pip install streamlit\n",
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install tiktoken\n",
        "!pip install sentence_transformers\n",
        "!pip install tiktoken\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D2sXW7Unmcm",
        "outputId": "12bb330d-bd3e-4904-aa62-1181d62f0810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/colab_content/gist.py\n"
          ]
        }
      ],
      "source": [
        "# This writes the code to the VM on which this notebook runs.\n",
        "\n",
        "%%writefile /content/drive/MyDrive/colab_content/gist.py\n",
        "\n",
        "\n",
        "# from scipy import spatial\n",
        "# import ast  # for converting embeddings saved as strings back to arrays\n",
        "# import openai  # for calling the OpenAI API\n",
        "# import pandas as pd  # for storing text and embeddings data\n",
        "# import tiktoken  # for counting tokens\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "PAGE_CONFIG = {\"page_title\": \"Hello baby!\", \"page_icon\": \"smiley\", \"layout\": \"centered\"}\n",
        "st.set_page_config(**PAGE_CONFIG)\n",
        "st.title(\"Welcome to our world!\")\n",
        "st.subheader(\"We are head over heels!\")\n",
        "pdf = st.file_uploader(\"Upload your PDF\", type = \"PDF\")\n",
        "\n",
        "if pdf is not None:\n",
        "    pdf_reader = PdfReader(pdf)\n",
        "    content = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        content += page.extract_text()\n",
        "    # st.write(\"====Content====\")\n",
        "    # st.write(content)\n",
        "\n",
        "    # Chunk out the file\n",
        "    text_splitter = CharacterTextSplitter(separator=\" \", chunk_size= 160, chunk_overlap = 15, length_function= len)\n",
        "    chunks = text_splitter.split_text(content)\n",
        "\n",
        "    # st.write(\"====Chunks====\")\n",
        "    # st.write(chunks)\n",
        "\n",
        "    #Ask the question\n",
        "    question = st.text_input(\"Ask me something about the PDF that you just uploaded:\")\n",
        "    if question:\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "\n",
        "        # These are the vectorized chunks:\n",
        "        knowledge_base = FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "        # Docs are those vectors that are similar to the vectors in the knowledge base.\n",
        "        docs = knowledge_base.similarity_search(question)\n",
        "\n",
        "        if docs is not None:\n",
        "            st.write(\"These are the related chunks:\")\n",
        "            for doc in docs:\n",
        "                st.write(doc)\n",
        "            \n",
        "            # Forward the related chunks to the LLM with the query as a prompt\n",
        "            llm = OpenAI()\n",
        "        \n",
        "            chain = load_qa_chain(llm, chain_type = \"stuff\")\n",
        "            with get_openai_callback() as cb:\n",
        "                response = chain.run(question = question, input_documents = docs)\n",
        "                st.write(\"Cost of query:\")\n",
        "                st.write(cb)\n",
        "\n",
        "            st.write(response)\n",
        "        else:\n",
        "            st.write(\"No match on the chunks!\")\n",
        "\n",
        "\n",
        "# EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "# GPT_MODEL = \"gpt-3.5-turbo\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjCJuZHOngpy",
        "outputId": "7b180efd-6461-492a-fd78-ece907ca4d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-06-11T12:29:39+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the URL that can be used to access the Streamlit app NgrokTunnel: \"https://fdb2-34-134-54-16.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "# Set up the tunnel to allow access to the running Streamlit instance.\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ['STREAMLIT_SERVER_MAX_UPLOAD_SIZE']='201'\n",
        "with open('/content/drive/MyDrive/colab_content/api-keys.txt', 'r') as f:\n",
        "    api_key_list = f.readlines()\n",
        "for kv in api_key_list:\n",
        "    k,v = kv.split('=')\n",
        "    #print(k, v)\n",
        "    os.environ[k] = v.strip()\n",
        "ngrok_token = os.getenv('NGROK_AUTH_TOKEN').strip()\n",
        "!ngrok authtoken $ngrok_token\n",
        "public_url = ngrok.connect(addr='8501') # This is the default Streamlit port\n",
        "print('This is the URL that can be used to access the Streamlit app', public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgLS6Yg-b2k2"
      },
      "outputs": [],
      "source": [
        "# Start the streamlit app and leave it running and then access the running app at the URL above.\n",
        "\n",
        "!streamlit run /content/drive/MyDrive/colab_content/gist.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM4otw2F/PHn3CCeCSs1G85",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
